{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOfMQpQpDOifFEAqCVxEEe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinYeongPark/AI_practice/blob/main/221017%EC%8B%A4%EC%8A%B5_4_%EC%9D%B8%EA%B3%B5_%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%98_%EB%AC%B8%EC%A0%9C%EC%A0%90(%EA%B8%B0%EC%9A%B8%EA%B8%B0_%EB%AC%B8%EC%A0%9C).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P8xpejOuWno1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 기울기 소실/폭발 문제 확인 : Vanishing/Exploding Gradient"
      ],
      "metadata": {
        "id": "swvc_qQ-W1TR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x)) # sigmoid 함수의 수식"
      ],
      "metadata": {
        "id": "3ipZtKWPW77q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(-5.0, 5, 0.1) # -5.0 ~ 5.0까지 0.1씩 증가\n",
        "y = sigmoid(x)\n",
        "plt.plot(x,y) # 무조건 값이 0과 1 사이로 제한이 되어버림"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "V3aCNIUkXCG8",
        "outputId": "ad97440c-8a6b-4ad2-dfd2-d898e74ddfc4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f91d0cca550>]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff_y = sigmoid(x) * (1-sigmoid(x))\n",
        "plt.plot(x, diff_y) # 미분할 경우 최대값이 0.25에 불과\n",
        "# 미분한 값이 0 ~ 0.25 사이"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "satadPfeXFe9",
        "outputId": "224c9ca9-7169-4b3c-b87a-44ff4f773e3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f923e9d3110>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 기울기 소실/폭발 : 활성화 함수를 변경하여 해결"
      ],
      "metadata": {
        "id": "zgfyTPqDXr6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 가중치가 업데이트 되었다는 건 loss도 같이 줄어든다는 뜻\n",
        "# -> 무조건은 아님, local minima와 global minima \n",
        "# -> 근데 이렇게 간단한 형태의 데이터와 모델에서 봤을 때, 가중치가 업데이트 되면 loss도 같이 업데이트 될 확률이 높음\n",
        "# -> 아직 과적합은 고려하지 않고 진행 "
      ],
      "metadata": {
        "id": "_nq4jKvfs3WQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1017)\n",
        "\n",
        "inputs = torch.randn(2, 2) # 2행 2열 짜리 데이터\n",
        "\n",
        "sigmoid_network = nn.Sequential(\n",
        "    nn.Linear(2,1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "sigmoid_network[0].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZYeR0LtXZDg",
        "outputId": "f915e3f6-b082-4932-878c-9ebe04056769"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0430, -0.3409]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(777)\n",
        "\n",
        "targets = torch.randn(2) # 각 행마다 해당하는 label을 생성"
      ],
      "metadata": {
        "id": "GIqKcBsMYOsb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 업데이트에 필요한 요소들 설정 : 뒤에가서 하나씩 살펴볼 예정, 지금은 이런게 있어야 업데이트가 되는구나 정도로 이해\n",
        "learning_rate = 0.001 # 학습률\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(sigmoid_network.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "O3BNpJzXYUiI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "vFehm22OZM3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(0, 100) : # 에폭 : 한번 학습하는 것 - 총 100번 돌아가게 하겠다.\n",
        "    print('*** Start {} Epoch'.format(epoch+1)) # epoch마다 시작되는 걸 보겠다\n",
        "    sigmoid_network.train() # 학습모드로 설정\n",
        "\n",
        "    pred = sigmoid_network(inputs) # 예측값 할당\n",
        "\n",
        "    loss = criterion(targets, pred) # loss값 계산\n",
        "    print('Loss : {}'.format(loss)) # loss값을 에포크마다 보겠다.\n",
        "    \n",
        "    optimizer.zero_grad() # # 기울기가 누적되는 것을 방지하기 위해 기울기를 0으로 초기화 - 안에 있는 것들을 다 0으로 만들겠다는 메서드.\n",
        "    loss.backward() # loss 값을 통해서 편미분\n",
        "    optimizer.step() # 가중치를 한 스텝 업데이트\n",
        "\n",
        "    print('Weight : {}'.format(sigmoid_network[0].weight), '\\n') # 가중치를 epoch마다 보겠다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__ZD033HYk9q",
        "outputId": "66ac8bb9-7748-42c6-c4f5-56d8aae9abe1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Start 1 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0420, -0.3399]], requires_grad=True) \n",
            "\n",
            "*** Start 2 Epoch\n",
            "Loss : 0.9606472253799438\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0410, -0.3389]], requires_grad=True) \n",
            "\n",
            "*** Start 3 Epoch\n",
            "Loss : 0.9596229791641235\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0400, -0.3379]], requires_grad=True) \n",
            "\n",
            "*** Start 4 Epoch\n",
            "Loss : 0.958599328994751\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0390, -0.3369]], requires_grad=True) \n",
            "\n",
            "*** Start 5 Epoch\n",
            "Loss : 0.9575760364532471\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0380, -0.3359]], requires_grad=True) \n",
            "\n",
            "*** Start 6 Epoch\n",
            "Loss : 0.9565534591674805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight : Parameter containing:\n",
            "tensor([[-0.0370, -0.3349]], requires_grad=True) \n",
            "\n",
            "*** Start 7 Epoch\n",
            "Loss : 0.9555312991142273\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0360, -0.3339]], requires_grad=True) \n",
            "\n",
            "*** Start 8 Epoch\n",
            "Loss : 0.9545097947120667\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0350, -0.3329]], requires_grad=True) \n",
            "\n",
            "*** Start 9 Epoch\n",
            "Loss : 0.9534887671470642\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0340, -0.3319]], requires_grad=True) \n",
            "\n",
            "*** Start 10 Epoch\n",
            "Loss : 0.9524683952331543\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0330, -0.3309]], requires_grad=True) \n",
            "\n",
            "*** Start 11 Epoch\n",
            "Loss : 0.9514485597610474\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0320, -0.3299]], requires_grad=True) \n",
            "\n",
            "*** Start 12 Epoch\n",
            "Loss : 0.9504291415214539\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0310, -0.3289]], requires_grad=True) \n",
            "\n",
            "*** Start 13 Epoch\n",
            "Loss : 0.9494105577468872\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0300, -0.3279]], requires_grad=True) \n",
            "\n",
            "*** Start 14 Epoch\n",
            "Loss : 0.9483925104141235\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0290, -0.3269]], requires_grad=True) \n",
            "\n",
            "*** Start 15 Epoch\n",
            "Loss : 0.9473751187324524\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0280, -0.3259]], requires_grad=True) \n",
            "\n",
            "*** Start 16 Epoch\n",
            "Loss : 0.9463584423065186\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0270, -0.3249]], requires_grad=True) \n",
            "\n",
            "*** Start 17 Epoch\n",
            "Loss : 0.9453422427177429\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0260, -0.3239]], requires_grad=True) \n",
            "\n",
            "*** Start 18 Epoch\n",
            "Loss : 0.9443268179893494\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0250, -0.3229]], requires_grad=True) \n",
            "\n",
            "*** Start 19 Epoch\n",
            "Loss : 0.9433121681213379\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0240, -0.3219]], requires_grad=True) \n",
            "\n",
            "*** Start 20 Epoch\n",
            "Loss : 0.9422979354858398\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0230, -0.3209]], requires_grad=True) \n",
            "\n",
            "*** Start 21 Epoch\n",
            "Loss : 0.9412845969200134\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0220, -0.3199]], requires_grad=True) \n",
            "\n",
            "*** Start 22 Epoch\n",
            "Loss : 0.9402719736099243\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0210, -0.3189]], requires_grad=True) \n",
            "\n",
            "*** Start 23 Epoch\n",
            "Loss : 0.939259946346283\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0200, -0.3179]], requires_grad=True) \n",
            "\n",
            "*** Start 24 Epoch\n",
            "Loss : 0.9382487535476685\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0190, -0.3169]], requires_grad=True) \n",
            "\n",
            "*** Start 25 Epoch\n",
            "Loss : 0.9372382164001465\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0180, -0.3159]], requires_grad=True) \n",
            "\n",
            "*** Start 26 Epoch\n",
            "Loss : 0.9362283945083618\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0170, -0.3149]], requires_grad=True) \n",
            "\n",
            "*** Start 27 Epoch\n",
            "Loss : 0.935219407081604\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0160, -0.3139]], requires_grad=True) \n",
            "\n",
            "*** Start 28 Epoch\n",
            "Loss : 0.934211254119873\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0150, -0.3129]], requires_grad=True) \n",
            "\n",
            "*** Start 29 Epoch\n",
            "Loss : 0.9332038164138794\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0140, -0.3119]], requires_grad=True) \n",
            "\n",
            "*** Start 30 Epoch\n",
            "Loss : 0.9321969747543335\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0130, -0.3110]], requires_grad=True) \n",
            "\n",
            "*** Start 31 Epoch\n",
            "Loss : 0.931191086769104\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0120, -0.3100]], requires_grad=True) \n",
            "\n",
            "*** Start 32 Epoch\n",
            "Loss : 0.9301859140396118\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0110, -0.3090]], requires_grad=True) \n",
            "\n",
            "*** Start 33 Epoch\n",
            "Loss : 0.9291816353797913\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0100, -0.3080]], requires_grad=True) \n",
            "\n",
            "*** Start 34 Epoch\n",
            "Loss : 0.9281781911849976\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0090, -0.3070]], requires_grad=True) \n",
            "\n",
            "*** Start 35 Epoch\n",
            "Loss : 0.9271755218505859\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0080, -0.3060]], requires_grad=True) \n",
            "\n",
            "*** Start 36 Epoch\n",
            "Loss : 0.9261735677719116\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0070, -0.3050]], requires_grad=True) \n",
            "\n",
            "*** Start 37 Epoch\n",
            "Loss : 0.9251725673675537\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0061, -0.3040]], requires_grad=True) \n",
            "\n",
            "*** Start 38 Epoch\n",
            "Loss : 0.9241723418235779\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0051, -0.3030]], requires_grad=True) \n",
            "\n",
            "*** Start 39 Epoch\n",
            "Loss : 0.9231730103492737\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0041, -0.3020]], requires_grad=True) \n",
            "\n",
            "*** Start 40 Epoch\n",
            "Loss : 0.9221744537353516\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0031, -0.3010]], requires_grad=True) \n",
            "\n",
            "*** Start 41 Epoch\n",
            "Loss : 0.9211767911911011\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0021, -0.3000]], requires_grad=True) \n",
            "\n",
            "*** Start 42 Epoch\n",
            "Loss : 0.920180082321167\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0011, -0.2990]], requires_grad=True) \n",
            "\n",
            "*** Start 43 Epoch\n",
            "Loss : 0.9191842079162598\n",
            "Weight : Parameter containing:\n",
            "tensor([[-9.5799e-05, -2.9801e-01]], requires_grad=True) \n",
            "\n",
            "*** Start 44 Epoch\n",
            "Loss : 0.9181891083717346\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0009, -0.2970]], requires_grad=True) \n",
            "\n",
            "*** Start 45 Epoch\n",
            "Loss : 0.9171950817108154\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0019, -0.2960]], requires_grad=True) \n",
            "\n",
            "*** Start 46 Epoch\n",
            "Loss : 0.9162017107009888\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0029, -0.2950]], requires_grad=True) \n",
            "\n",
            "*** Start 47 Epoch\n",
            "Loss : 0.9152094125747681\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0039, -0.2940]], requires_grad=True) \n",
            "\n",
            "*** Start 48 Epoch\n",
            "Loss : 0.9142179489135742\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0049, -0.2930]], requires_grad=True) \n",
            "\n",
            "*** Start 49 Epoch\n",
            "Loss : 0.9132273197174072\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0059, -0.2921]], requires_grad=True) \n",
            "\n",
            "*** Start 50 Epoch\n",
            "Loss : 0.9122377634048462\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0068, -0.2911]], requires_grad=True) \n",
            "\n",
            "*** Start 51 Epoch\n",
            "Loss : 0.9112489223480225\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0078, -0.2901]], requires_grad=True) \n",
            "\n",
            "*** Start 52 Epoch\n",
            "Loss : 0.9102611541748047\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0088, -0.2891]], requires_grad=True) \n",
            "\n",
            "*** Start 53 Epoch\n",
            "Loss : 0.9092742204666138\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0098, -0.2881]], requires_grad=True) \n",
            "\n",
            "*** Start 54 Epoch\n",
            "Loss : 0.9082883596420288\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0108, -0.2871]], requires_grad=True) \n",
            "\n",
            "*** Start 55 Epoch\n",
            "Loss : 0.9073033332824707\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0118, -0.2861]], requires_grad=True) \n",
            "\n",
            "*** Start 56 Epoch\n",
            "Loss : 0.906319260597229\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0128, -0.2851]], requires_grad=True) \n",
            "\n",
            "*** Start 57 Epoch\n",
            "Loss : 0.9053362607955933\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0138, -0.2841]], requires_grad=True) \n",
            "\n",
            "*** Start 58 Epoch\n",
            "Loss : 0.9043540358543396\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0148, -0.2831]], requires_grad=True) \n",
            "\n",
            "*** Start 59 Epoch\n",
            "Loss : 0.9033728837966919\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0157, -0.2822]], requires_grad=True) \n",
            "\n",
            "*** Start 60 Epoch\n",
            "Loss : 0.902392566204071\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0167, -0.2812]], requires_grad=True) \n",
            "\n",
            "*** Start 61 Epoch\n",
            "Loss : 0.9014133214950562\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0177, -0.2802]], requires_grad=True) \n",
            "\n",
            "*** Start 62 Epoch\n",
            "Loss : 0.9004349708557129\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0187, -0.2792]], requires_grad=True) \n",
            "\n",
            "*** Start 63 Epoch\n",
            "Loss : 0.8994576334953308\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0197, -0.2782]], requires_grad=True) \n",
            "\n",
            "*** Start 64 Epoch\n",
            "Loss : 0.8984813094139099\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0207, -0.2772]], requires_grad=True) \n",
            "\n",
            "*** Start 65 Epoch\n",
            "Loss : 0.8975059986114502\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0217, -0.2762]], requires_grad=True) \n",
            "\n",
            "*** Start 66 Epoch\n",
            "Loss : 0.8965315818786621\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0226, -0.2752]], requires_grad=True) \n",
            "\n",
            "*** Start 67 Epoch\n",
            "Loss : 0.89555823802948\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0236, -0.2743]], requires_grad=True) \n",
            "\n",
            "*** Start 68 Epoch\n",
            "Loss : 0.8945858478546143\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0246, -0.2733]], requires_grad=True) \n",
            "\n",
            "*** Start 69 Epoch\n",
            "Loss : 0.8936142921447754\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0256, -0.2723]], requires_grad=True) \n",
            "\n",
            "*** Start 70 Epoch\n",
            "Loss : 0.8926440477371216\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0266, -0.2713]], requires_grad=True) \n",
            "\n",
            "*** Start 71 Epoch\n",
            "Loss : 0.8916746973991394\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0276, -0.2703]], requires_grad=True) \n",
            "\n",
            "*** Start 72 Epoch\n",
            "Loss : 0.8907063603401184\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0286, -0.2693]], requires_grad=True) \n",
            "\n",
            "*** Start 73 Epoch\n",
            "Loss : 0.8897390365600586\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0295, -0.2683]], requires_grad=True) \n",
            "\n",
            "*** Start 74 Epoch\n",
            "Loss : 0.88877272605896\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0305, -0.2674]], requires_grad=True) \n",
            "\n",
            "*** Start 75 Epoch\n",
            "Loss : 0.8878074884414673\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0315, -0.2664]], requires_grad=True) \n",
            "\n",
            "*** Start 76 Epoch\n",
            "Loss : 0.8868431448936462\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0325, -0.2654]], requires_grad=True) \n",
            "\n",
            "*** Start 77 Epoch\n",
            "Loss : 0.8858799338340759\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0335, -0.2644]], requires_grad=True) \n",
            "\n",
            "*** Start 78 Epoch\n",
            "Loss : 0.8849177360534668\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0344, -0.2634]], requires_grad=True) \n",
            "\n",
            "*** Start 79 Epoch\n",
            "Loss : 0.8839566707611084\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0354, -0.2624]], requires_grad=True) \n",
            "\n",
            "*** Start 80 Epoch\n",
            "Loss : 0.8829965591430664\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0364, -0.2615]], requires_grad=True) \n",
            "\n",
            "*** Start 81 Epoch\n",
            "Loss : 0.8820375800132751\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0374, -0.2605]], requires_grad=True) \n",
            "\n",
            "*** Start 82 Epoch\n",
            "Loss : 0.8810795545578003\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0384, -0.2595]], requires_grad=True) \n",
            "\n",
            "*** Start 83 Epoch\n",
            "Loss : 0.8801226615905762\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0394, -0.2585]], requires_grad=True) \n",
            "\n",
            "*** Start 84 Epoch\n",
            "Loss : 0.8791667819023132\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0403, -0.2575]], requires_grad=True) \n",
            "\n",
            "*** Start 85 Epoch\n",
            "Loss : 0.8782119750976562\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0413, -0.2566]], requires_grad=True) \n",
            "\n",
            "*** Start 86 Epoch\n",
            "Loss : 0.8772581815719604\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0423, -0.2556]], requires_grad=True) \n",
            "\n",
            "*** Start 87 Epoch\n",
            "Loss : 0.8763055801391602\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0433, -0.2546]], requires_grad=True) \n",
            "\n",
            "*** Start 88 Epoch\n",
            "Loss : 0.875353991985321\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0442, -0.2536]], requires_grad=True) \n",
            "\n",
            "*** Start 89 Epoch\n",
            "Loss : 0.8744034767150879\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0452, -0.2526]], requires_grad=True) \n",
            "\n",
            "*** Start 90 Epoch\n",
            "Loss : 0.8734541535377502\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0462, -0.2517]], requires_grad=True) \n",
            "\n",
            "*** Start 91 Epoch\n",
            "Loss : 0.872505784034729\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0472, -0.2507]], requires_grad=True) \n",
            "\n",
            "*** Start 92 Epoch\n",
            "Loss : 0.8715585470199585\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0482, -0.2497]], requires_grad=True) \n",
            "\n",
            "*** Start 93 Epoch\n",
            "Loss : 0.8706122636795044\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0491, -0.2487]], requires_grad=True) \n",
            "\n",
            "*** Start 94 Epoch\n",
            "Loss : 0.8696673512458801\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0501, -0.2478]], requires_grad=True) \n",
            "\n",
            "*** Start 95 Epoch\n",
            "Loss : 0.8687233924865723\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0511, -0.2468]], requires_grad=True) \n",
            "\n",
            "*** Start 96 Epoch\n",
            "Loss : 0.8677805662155151\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0521, -0.2458]], requires_grad=True) \n",
            "\n",
            "*** Start 97 Epoch\n",
            "Loss : 0.866838812828064\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0530, -0.2448]], requires_grad=True) \n",
            "\n",
            "*** Start 98 Epoch\n",
            "Loss : 0.8658981919288635\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0540, -0.2439]], requires_grad=True) \n",
            "\n",
            "*** Start 99 Epoch\n",
            "Loss : 0.864958643913269\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0550, -0.2429]], requires_grad=True) \n",
            "\n",
            "*** Start 100 Epoch\n",
            "Loss : 0.8640202879905701\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0560, -0.2419]], requires_grad=True) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#relu 쓰는 것\n",
        "torch.manual_seed(1017)\n",
        "\n",
        "inputs = torch.randn(2, 2) # 2행 2열 짜리 데이터\n",
        "\n",
        "relu_network = nn.Sequential(\n",
        "    nn.Linear(2,1),\n",
        "    nn.ReLU()\n",
        ")"
      ],
      "metadata": {
        "id": "P6HJR7ZLZ4YP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001 # 학습률\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(relu_network.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "JmdH3q6QbEtC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과를 확인하면, sigmoid를 사용한 모델에 비해서 loss가 현저하게 줄어든 것을 확인할 수 있음\n",
        "# -> 가중치가 잘 업데이트 되고 있다는 뜻\n",
        "\n",
        "for epoch in range(0, 100) : # 에폭 : 한번 학습하는 것 - 총 100번 돌아가게 하겠다.\n",
        "    print('*** Start {} Epoch'.format(epoch+1)) # epoch마다 시작되는 걸 보겠다\n",
        "    relu_network.train() # 학습모드로 설정\n",
        "\n",
        "    pred = relu_network(inputs) # 예측값 할당\n",
        "\n",
        "    loss = criterion(targets, pred) # loss값 계산\n",
        "    print('Loss : {}'.format(loss)) # loss값을 에포크마다 보겠다.\n",
        "    \n",
        "    optimizer.zero_grad() # 기울기가 누적이 되는 걸 방지 - 안에 있는 것들을 다 0으로 만들겠다는 메서드.\n",
        "    loss.backward() # loss 값을 통해서 편미분\n",
        "    optimizer.step() # 가중치를 한 스텝 업데이트\n",
        "\n",
        "    print('Weight : {}'.format(relu_network[0].weight), '\\n') # 가중치를 epoch마다 보겠다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gKEg0QabJqA",
        "outputId": "947a9c7f-8955-45a0-ee17-0f3021bce2c0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Start 1 Epoch\n",
            "Loss : 0.36954379081726074\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0420, -0.3399]], requires_grad=True) \n",
            "\n",
            "*** Start 2 Epoch\n",
            "Loss : 0.3676071763038635\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0410, -0.3389]], requires_grad=True) \n",
            "\n",
            "*** Start 3 Epoch\n",
            "Loss : 0.36567872762680054\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0400, -0.3379]], requires_grad=True) \n",
            "\n",
            "*** Start 4 Epoch\n",
            "Loss : 0.36375853419303894\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0390, -0.3369]], requires_grad=True) \n",
            "\n",
            "*** Start 5 Epoch\n",
            "Loss : 0.36184680461883545\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0380, -0.3359]], requires_grad=True) \n",
            "\n",
            "*** Start 6 Epoch\n",
            "Loss : 0.3599436283111572\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0370, -0.3349]], requires_grad=True) \n",
            "\n",
            "*** Start 7 Epoch\n",
            "Loss : 0.3580492436885834\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0360, -0.3339]], requires_grad=True) \n",
            "\n",
            "*** Start 8 Epoch\n",
            "Loss : 0.3561636209487915\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0350, -0.3329]], requires_grad=True) \n",
            "\n",
            "*** Start 9 Epoch\n",
            "Loss : 0.35428696870803833\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0340, -0.3319]], requires_grad=True) \n",
            "\n",
            "*** Start 10 Epoch\n",
            "Loss : 0.352419376373291\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0330, -0.3309]], requires_grad=True) \n",
            "\n",
            "*** Start 11 Epoch\n",
            "Loss : 0.3505609631538391\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0320, -0.3299]], requires_grad=True) \n",
            "\n",
            "*** Start 12 Epoch\n",
            "Loss : 0.34871190786361694\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0310, -0.3289]], requires_grad=True) \n",
            "\n",
            "*** Start 13 Epoch\n",
            "Loss : 0.3468722403049469\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0300, -0.3279]], requires_grad=True) \n",
            "\n",
            "*** Start 14 Epoch\n",
            "Loss : 0.34504204988479614\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0290, -0.3270]], requires_grad=True) \n",
            "\n",
            "*** Start 15 Epoch\n",
            "Loss : 0.3432214856147766\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0280, -0.3260]], requires_grad=True) \n",
            "\n",
            "*** Start 16 Epoch\n",
            "Loss : 0.3414106070995331\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0270, -0.3250]], requires_grad=True) \n",
            "\n",
            "*** Start 17 Epoch\n",
            "Loss : 0.3396095335483551\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0260, -0.3240]], requires_grad=True) \n",
            "\n",
            "*** Start 18 Epoch\n",
            "Loss : 0.33781835436820984\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0251, -0.3230]], requires_grad=True) \n",
            "\n",
            "*** Start 19 Epoch\n",
            "Loss : 0.3360370695590973\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0241, -0.3220]], requires_grad=True) \n",
            "\n",
            "*** Start 20 Epoch\n",
            "Loss : 0.33426588773727417\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0231, -0.3210]], requires_grad=True) \n",
            "\n",
            "*** Start 21 Epoch\n",
            "Loss : 0.3325047492980957\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0221, -0.3200]], requires_grad=True) \n",
            "\n",
            "*** Start 22 Epoch\n",
            "Loss : 0.33075374364852905\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0211, -0.3191]], requires_grad=True) \n",
            "\n",
            "*** Start 23 Epoch\n",
            "Loss : 0.32901301980018616\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0201, -0.3181]], requires_grad=True) \n",
            "\n",
            "*** Start 24 Epoch\n",
            "Loss : 0.32728254795074463\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0192, -0.3171]], requires_grad=True) \n",
            "\n",
            "*** Start 25 Epoch\n",
            "Loss : 0.32556241750717163\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0182, -0.3161]], requires_grad=True) \n",
            "\n",
            "*** Start 26 Epoch\n",
            "Loss : 0.3238525986671448\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0172, -0.3151]], requires_grad=True) \n",
            "\n",
            "*** Start 27 Epoch\n",
            "Loss : 0.3221532106399536\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0162, -0.3142]], requires_grad=True) \n",
            "\n",
            "*** Start 28 Epoch\n",
            "Loss : 0.3204643130302429\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0152, -0.3132]], requires_grad=True) \n",
            "\n",
            "*** Start 29 Epoch\n",
            "Loss : 0.3187858760356903\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0143, -0.3122]], requires_grad=True) \n",
            "\n",
            "*** Start 30 Epoch\n",
            "Loss : 0.31711792945861816\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0133, -0.3112]], requires_grad=True) \n",
            "\n",
            "*** Start 31 Epoch\n",
            "Loss : 0.3154604732990265\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0123, -0.3103]], requires_grad=True) \n",
            "\n",
            "*** Start 32 Epoch\n",
            "Loss : 0.31381362676620483\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0114, -0.3093]], requires_grad=True) \n",
            "\n",
            "*** Start 33 Epoch\n",
            "Loss : 0.31217724084854126\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0104, -0.3083]], requires_grad=True) \n",
            "\n",
            "*** Start 34 Epoch\n",
            "Loss : 0.31055155396461487\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0094, -0.3074]], requires_grad=True) \n",
            "\n",
            "*** Start 35 Epoch\n",
            "Loss : 0.30893635749816895\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0085, -0.3064]], requires_grad=True) \n",
            "\n",
            "*** Start 36 Epoch\n",
            "Loss : 0.30733177065849304\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0075, -0.3055]], requires_grad=True) \n",
            "\n",
            "*** Start 37 Epoch\n",
            "Loss : 0.3057377338409424\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0066, -0.3045]], requires_grad=True) \n",
            "\n",
            "*** Start 38 Epoch\n",
            "Loss : 0.30415433645248413\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0056, -0.3035]], requires_grad=True) \n",
            "\n",
            "*** Start 39 Epoch\n",
            "Loss : 0.3025815188884735\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0047, -0.3026]], requires_grad=True) \n",
            "\n",
            "*** Start 40 Epoch\n",
            "Loss : 0.30101922154426575\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0037, -0.3016]], requires_grad=True) \n",
            "\n",
            "*** Start 41 Epoch\n",
            "Loss : 0.2994675040245056\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0028, -0.3007]], requires_grad=True) \n",
            "\n",
            "*** Start 42 Epoch\n",
            "Loss : 0.2979263961315155\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0018, -0.2998]], requires_grad=True) \n",
            "\n",
            "*** Start 43 Epoch\n",
            "Loss : 0.29639580845832825\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0009, -0.2988]], requires_grad=True) \n",
            "\n",
            "*** Start 44 Epoch\n",
            "Loss : 0.2948756814002991\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 7.7481e-05, -2.9786e-01]], requires_grad=True) \n",
            "\n",
            "*** Start 45 Epoch\n",
            "Loss : 0.29336610436439514\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0010, -0.2969]], requires_grad=True) \n",
            "\n",
            "*** Start 46 Epoch\n",
            "Loss : 0.2918670177459717\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0020, -0.2960]], requires_grad=True) \n",
            "\n",
            "*** Start 47 Epoch\n",
            "Loss : 0.2903783321380615\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0029, -0.2950]], requires_grad=True) \n",
            "\n",
            "*** Start 48 Epoch\n",
            "Loss : 0.28890007734298706\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0038, -0.2941]], requires_grad=True) \n",
            "\n",
            "*** Start 49 Epoch\n",
            "Loss : 0.2874322831630707\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0048, -0.2932]], requires_grad=True) \n",
            "\n",
            "*** Start 50 Epoch\n",
            "Loss : 0.2859748303890228\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0057, -0.2923]], requires_grad=True) \n",
            "\n",
            "*** Start 51 Epoch\n",
            "Loss : 0.2845277786254883\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0066, -0.2913]], requires_grad=True) \n",
            "\n",
            "*** Start 52 Epoch\n",
            "Loss : 0.2830909788608551\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0075, -0.2904]], requires_grad=True) \n",
            "\n",
            "*** Start 53 Epoch\n",
            "Loss : 0.2816644608974457\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0085, -0.2895]], requires_grad=True) \n",
            "\n",
            "*** Start 54 Epoch\n",
            "Loss : 0.2802482843399048\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0094, -0.2886]], requires_grad=True) \n",
            "\n",
            "*** Start 55 Epoch\n",
            "Loss : 0.2788422703742981\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0103, -0.2876]], requires_grad=True) \n",
            "\n",
            "*** Start 56 Epoch\n",
            "Loss : 0.277446448802948\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0112, -0.2867]], requires_grad=True) \n",
            "\n",
            "*** Start 57 Epoch\n",
            "Loss : 0.2760608196258545\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0121, -0.2858]], requires_grad=True) \n",
            "\n",
            "*** Start 58 Epoch\n",
            "Loss : 0.2746853232383728\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0130, -0.2849]], requires_grad=True) \n",
            "\n",
            "*** Start 59 Epoch\n",
            "Loss : 0.27331987023353577\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0139, -0.2840]], requires_grad=True) \n",
            "\n",
            "*** Start 60 Epoch\n",
            "Loss : 0.271964430809021\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0149, -0.2831]], requires_grad=True) \n",
            "\n",
            "*** Start 61 Epoch\n",
            "Loss : 0.2706190347671509\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0158, -0.2822]], requires_grad=True) \n",
            "\n",
            "*** Start 62 Epoch\n",
            "Loss : 0.26928356289863586\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0167, -0.2813]], requires_grad=True) \n",
            "\n",
            "*** Start 63 Epoch\n",
            "Loss : 0.26795804500579834\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0176, -0.2804]], requires_grad=True) \n",
            "\n",
            "*** Start 64 Epoch\n",
            "Loss : 0.26664242148399353\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0185, -0.2795]], requires_grad=True) \n",
            "\n",
            "*** Start 65 Epoch\n",
            "Loss : 0.26533663272857666\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0194, -0.2786]], requires_grad=True) \n",
            "\n",
            "*** Start 66 Epoch\n",
            "Loss : 0.26404061913490295\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0202, -0.2777]], requires_grad=True) \n",
            "\n",
            "*** Start 67 Epoch\n",
            "Loss : 0.26275435090065\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0211, -0.2768]], requires_grad=True) \n",
            "\n",
            "*** Start 68 Epoch\n",
            "Loss : 0.26147782802581787\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0220, -0.2759]], requires_grad=True) \n",
            "\n",
            "*** Start 69 Epoch\n",
            "Loss : 0.2602109909057617\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0229, -0.2750]], requires_grad=True) \n",
            "\n",
            "*** Start 70 Epoch\n",
            "Loss : 0.2589537799358368\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0238, -0.2741]], requires_grad=True) \n",
            "\n",
            "*** Start 71 Epoch\n",
            "Loss : 0.2577061653137207\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0247, -0.2733]], requires_grad=True) \n",
            "\n",
            "*** Start 72 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0255, -0.2725]], requires_grad=True) \n",
            "\n",
            "*** Start 73 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0262, -0.2717]], requires_grad=True) \n",
            "\n",
            "*** Start 74 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0269, -0.2711]], requires_grad=True) \n",
            "\n",
            "*** Start 75 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0274, -0.2705]], requires_grad=True) \n",
            "\n",
            "*** Start 76 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0280, -0.2700]], requires_grad=True) \n",
            "\n",
            "*** Start 77 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0285, -0.2695]], requires_grad=True) \n",
            "\n",
            "*** Start 78 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0289, -0.2690]], requires_grad=True) \n",
            "\n",
            "*** Start 79 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0293, -0.2686]], requires_grad=True) \n",
            "\n",
            "*** Start 80 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0297, -0.2683]], requires_grad=True) \n",
            "\n",
            "*** Start 81 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0300, -0.2679]], requires_grad=True) \n",
            "\n",
            "*** Start 82 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0303, -0.2676]], requires_grad=True) \n",
            "\n",
            "*** Start 83 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0306, -0.2674]], requires_grad=True) \n",
            "\n",
            "*** Start 84 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0308, -0.2671]], requires_grad=True) \n",
            "\n",
            "*** Start 85 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0310, -0.2669]], requires_grad=True) \n",
            "\n",
            "*** Start 86 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0312, -0.2667]], requires_grad=True) \n",
            "\n",
            "*** Start 87 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0314, -0.2665]], requires_grad=True) \n",
            "\n",
            "*** Start 88 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0316, -0.2664]], requires_grad=True) \n",
            "\n",
            "*** Start 89 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0317, -0.2662]], requires_grad=True) \n",
            "\n",
            "*** Start 90 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0319, -0.2661]], requires_grad=True) \n",
            "\n",
            "*** Start 91 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0320, -0.2660]], requires_grad=True) \n",
            "\n",
            "*** Start 92 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0321, -0.2658]], requires_grad=True) \n",
            "\n",
            "*** Start 93 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0322, -0.2657]], requires_grad=True) \n",
            "\n",
            "*** Start 94 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0323, -0.2656]], requires_grad=True) \n",
            "\n",
            "*** Start 95 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0324, -0.2656]], requires_grad=True) \n",
            "\n",
            "*** Start 96 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0324, -0.2655]], requires_grad=True) \n",
            "\n",
            "*** Start 97 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0325, -0.2654]], requires_grad=True) \n",
            "\n",
            "*** Start 98 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0326, -0.2654]], requires_grad=True) \n",
            "\n",
            "*** Start 99 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0326, -0.2653]], requires_grad=True) \n",
            "\n",
            "*** Start 100 Epoch\n",
            "Loss : 0.2566312849521637\n",
            "Weight : Parameter containing:\n",
            "tensor([[ 0.0327, -0.2653]], requires_grad=True) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 기울기 소실/폭발 : 학습률을 변경하여 해결"
      ],
      "metadata": {
        "id": "yftnlBWcbo4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델은 활성화 함수로 sigmoid를 사용한 모델로 고정\n",
        "\n",
        "torch.manual_seed(1017)\n",
        "\n",
        "inputs = torch.randn(2, 2) # 2행 2열 짜리 데이터\n",
        "\n",
        "sigmoid_network = nn.Sequential(\n",
        "    nn.Linear(2,1),\n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "eWsBh9cObSoM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01 # 학습률 # 기존 학습률에 10배를 적용\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(sigmoid_network.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "74NhvC9Tb6OR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 다른 조건은 그대로 두고 학습률만 바꿨는데 loss가 많이 내려간 것을 확인할 수 있음\n",
        "\n",
        "for epoch in range(0, 100) : # 에폭 : 한번 학습하는 것 - 총 100번 돌아가게 하겠다.\n",
        "    print('*** Start {} Epoch'.format(epoch+1)) # epoch마다 시작되는 걸 보겠다\n",
        "    sigmoid_network.train() # 학습모드로 설정\n",
        "\n",
        "    pred = sigmoid_network(inputs) # 예측값 할당\n",
        "\n",
        "    loss = criterion(targets, pred) # loss값 계산\n",
        "    print('Loss : {}'.format(loss)) # loss값을 에포크마다 보겠다.\n",
        "    \n",
        "    optimizer.zero_grad() # 기울기가 누적이 되는 걸 방지 - 안에 있는 것들을 다 0으로 만들겠다는 메서드.\n",
        "    loss.backward() # loss 값을 통해서 편미분\n",
        "    optimizer.step() # 가중치를 한 스텝 업데이트\n",
        "\n",
        "    print('Weight : {}'.format(sigmoid_network[0].weight), '\\n') # 가중치를 epoch마다 보겠다\n",
        "\n",
        "    # loss가 절반으로 확 떨어짐."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27ayCOZQcE05",
        "outputId": "00f5c2fb-f9ae-4033-b2b4-4d44d95d595c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Start 1 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 2 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 3 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 4 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 5 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 6 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 7 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 8 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 9 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 10 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 11 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 12 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 13 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 14 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 15 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 16 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 17 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 18 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 19 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 20 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 21 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 22 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 23 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 24 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 25 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 26 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 27 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 28 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 29 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 30 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 31 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 32 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 33 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 34 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 35 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 36 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 37 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 38 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 39 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 40 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 41 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 42 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 43 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 44 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 45 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 46 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 47 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 48 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 49 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 50 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 51 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 52 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 53 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 54 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 55 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 56 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 57 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 58 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 59 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 60 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 61 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 62 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 63 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 64 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 65 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 66 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 67 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 68 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 69 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 70 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 71 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 72 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 73 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 74 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 75 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 76 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 77 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 78 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 79 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 80 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 81 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 82 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 83 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 84 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 85 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 86 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 87 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 88 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 89 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 90 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 91 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 92 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 93 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 94 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 95 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 96 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 97 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 98 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 99 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n",
            "*** Start 100 Epoch\n",
            "Loss : 0.9616718888282776\n",
            "Weight : Parameter containing:\n",
            "tensor([[-0.0430, -0.3409]], requires_grad=True) \n",
            "\n"
          ]
        }
      ]
    }
  ]
}